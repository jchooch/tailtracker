{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from skimage.morphology import skeletonize\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.rcParams['xtick.labelsize'] = 20\n",
    "plt.rcParams['ytick.labelsize'] = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rotate_bound(image, angle):\n",
    "    #function from https://www.pyimagesearch.com/2017/01/02/rotate-images-correctly-with-opencv-and-python/\n",
    "    (h, w) = image.shape[:2]\n",
    "    (cX, cY) = (w // 2, h // 2)\n",
    "\n",
    "    M = cv2.getRotationMatrix2D((cX, cY), -angle, 1.0)\n",
    "    cos = np.abs(M[0, 0])\n",
    "    sin = np.abs(M[0, 1])\n",
    " \n",
    "    # compute the new bounding dimensions of the image\n",
    "    nW = int((h * sin) + (w * cos))\n",
    "    nH = int((h * cos) + (w * sin))\n",
    " \n",
    "    # adjust the rotation matrix to take into account translation\n",
    "    M[0, 2] += (nW / 2) - cX\n",
    "    M[1, 2] += (nH / 2) - cY\n",
    " \n",
    "    # perform the actual rotation and return the image\n",
    "    return cv2.warpAffine(image, M, (nW, nH))\n",
    "\n",
    "\n",
    "def distance_between(x1,y1,x2,y2):\n",
    "    dist = np.sqrt((x1-x2)**2+(y1-y2)**2)\n",
    "    return dist\n",
    "\n",
    "\n",
    "def get_polynomial_length(poly1d_object,xlims,stepsize=0.5):\n",
    "    \n",
    "    xs = np.arange(xlims[0],xlims[1],stepsize)\n",
    "    ys = poly1d_object(xs)\n",
    "    length = 0\n",
    "\n",
    "    for i in range(len(xs)-1):\n",
    "        length += distance_between(xs[i+1],ys[i+1],xs[i],ys[i])\n",
    "\n",
    "    return length\n",
    "\n",
    "\n",
    "def get_nearest_anchor_point(poly1d_object,xlims,point,stepsize=0.5):\n",
    "    xs = np.arange(xlims[0],xlims[1],stepsize)\n",
    "    ys = poly1d_object(xs)    \n",
    "    \n",
    "    nearest = xs[0]\n",
    "    prev_dist = distance_between(point[0],point[1],xs[0],ys[0])\n",
    "    \n",
    "    for i in range(len(xs)):\n",
    "    \n",
    "        dist = distance_between(point[0],point[1],xs[i],ys[i])\n",
    "        if dist <= prev_dist:\n",
    "            nearest = xs[i]\n",
    "    \n",
    "    newlims = [nearest,xlims[1]]\n",
    "    \n",
    "    return newlims\n",
    "\n",
    "\n",
    "def get_evenly_spaced_points(poly1d_object,xlims,stepsize=10):\n",
    "    xs = np.arange(xlims[0],xlims[1],1)\n",
    "    ys = poly1d_object(xs)\n",
    "    \n",
    "    xpoints = [xs[0]]\n",
    "    ypoints = [ys[0]]\n",
    "    dist = 0\n",
    "    for i in range(len(xs)-1):\n",
    "        dist += distance_between(xs[i],ys[i],xs[i+1],ys[i+1])\n",
    "        if dist>=stepsize:\n",
    "            xpoints.append(xs[i+1])\n",
    "            ypoints.append(ys[i+1])\n",
    "            dist = 0\n",
    "    \n",
    "    return (xpoints,ypoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "videofile = 'sample_300fps.avi'\n",
    "savevid = 'tracking.avi'\n",
    "\n",
    "outpath = '' \n",
    "\n",
    "\n",
    "savevideo = False\n",
    "savedata = True\n",
    "\n",
    "tailDirection = 2 # 1,2,3,4 => tail points left, right, up or down respectively in the video frame \n",
    "dispFrameInterval = 3 # ms to wait between frames that are displayed\n",
    "binThresh = 75 # Threshold for binarization. Needs to be adjusted for each fish\n",
    "polyfit_degree = 5 # Degree of polynomial to fit the contour of the tail\n",
    "numPoints = 100 # Number of points to describe the tail (for polynomial fitting)\n",
    "numDisplayPoints = 5 # Number of points to draw on the tail (for illustrative purposes)\n",
    "\n",
    "micronsPerPixel = 5 #assumes pixel aspect ratio of 1\n",
    "\n",
    "#Exercise caution while changing these\n",
    "claheBlockSize = (2,2)\n",
    "claheClipLim = 2.0\n",
    "blurBlockSize = (9,9)\n",
    "erodeBlockSize = (3,3)\n",
    "erodeIterations = 5\n",
    "distFraction = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0033333333333333335\n",
      "204.0\n",
      "256.0\n",
      "300.0\n",
      "1196444237.0\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(videofile)\n",
    "while not cap.isOpened():\n",
    "    pass\n",
    "\n",
    "width = 0\n",
    "height = 0\n",
    "if cap.isOpened(): \n",
    "    # get cap property \n",
    "    width = int(cap.get(3))\n",
    "    height = int(cap.get(4))\n",
    "    \n",
    "    \n",
    "clahe = cv2.createCLAHE(clipLimit=claheClipLim, tileGridSize=claheBlockSize)\n",
    "\n",
    "for i in [2,3,4,5,6]:\n",
    "    md = cap.get(i)\n",
    "    print (md)\n",
    "\n",
    "\n",
    "init = False\n",
    "if tailDirection == 1 or 2:\n",
    "    cl1 = np.ones((height,width),np.uint8)*255\n",
    "else:\n",
    "    cl1 = np.ones((width,height),np.uint8)*255\n",
    "\n",
    "while(cap.isOpened()):\n",
    "    \n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if ret==True:\n",
    "        \n",
    "        # Operations to be performed on all frames before tracking begins\n",
    "        \n",
    "        if tailDirection == 1:\n",
    "            frame = rotate_bound(frame,180)\n",
    "        if tailDirection == 3:\n",
    "            frame = rotate_bound(frame,90)\n",
    "        if tailDirection == 4:\n",
    "            frame = rotate_bound(frame,270)\n",
    "            \n",
    "        # 1) Contrast limited adaptive histogram equalization\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        cl1 = clahe.apply(gray)        \n",
    "        \n",
    "        # 2) Min projection of the equalized frames\n",
    "        if not init:\n",
    "            minProj = cl1\n",
    "            init = True\n",
    "\n",
    "        minProj = np.minimum(minProj,cl1)\n",
    "        \n",
    "        cv2.imshow('Background Estimation',minProj)\n",
    "\n",
    "        if cv2.waitKey(dispFrameInterval) & 0xFF == ord('q'):\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "        \n",
    "\n",
    "# Release everything if job is finished\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "# Callback Function for Trackbar\n",
    "def nothing(*arg):\n",
    "    pass\n",
    "\n",
    "def set_threshold(Image, WindowName):\n",
    "    # Generate trackbar Window Name\n",
    "    TrackbarName = WindowName + \"Trackbar\"\n",
    "\n",
    "    # Make Window and Trackbar\n",
    "    cv2.namedWindow(WindowName)\n",
    "    cv2.createTrackbar(TrackbarName, WindowName, 0, 255, nothing)\n",
    "\n",
    "    # Allocate destination image\n",
    "    Threshold = np.zeros(Image.shape, np.uint8)\n",
    "\n",
    "    # Loop for get trackbar pos and process it\n",
    "    while True:\n",
    "        # Get position in trackbar\n",
    "        TrackbarPos = cv2.getTrackbarPos(TrackbarName, WindowName)\n",
    "        # Apply threshold\n",
    "        cv2.threshold(Image, TrackbarPos, 255, cv2.THRESH_BINARY, Threshold)\n",
    "        # Show in window\n",
    "        cv2.imshow(WindowName, Threshold)\n",
    "\n",
    "        if cv2.waitKey(5) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cv2.destroyAllWindows()\n",
    "    return TrackbarPos\n",
    "\n",
    "binThresh = set_threshold(cl1-minProj,'Select Threshold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reconstruction Completed in 57.39s\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(videofile)\n",
    "    \n",
    "clahe = cv2.createCLAHE(clipLimit=claheClipLim, tileGridSize=claheBlockSize)\n",
    "\n",
    "# Define the codec and create VideoWriter object\n",
    "fourcc = cv2.VideoWriter_fourcc(*'MJPG')\n",
    "\n",
    "if savevideo :\n",
    "\n",
    "    if tailDirection == 1 or 2:\n",
    "        out = cv2.VideoWriter(savevid,fourcc, cap.get(5),(width,height))\n",
    "    else:\n",
    "        out = cv2.VideoWriter(savevid,fourcc, cap.get(5),(width,height))\n",
    "\n",
    "kernel = np.ones(erodeBlockSize,np.uint8)\n",
    "\n",
    "polyfit_object = []\n",
    "polyfit_coeffs = []\n",
    "xrange = []\n",
    "\n",
    "startTime = time.time()\n",
    "while(cap.isOpened()):\n",
    "    \n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if ret==True:\n",
    "        \n",
    "        if tailDirection == 1:\n",
    "            frame = rotate_bound(frame,180)\n",
    "        if tailDirection == 3:\n",
    "            frame = rotate_bound(frame,90)\n",
    "        if tailDirection == 4:\n",
    "            frame = rotate_bound(frame,270)\n",
    "        \n",
    "        # Contrast limited adaptive histogram equalization\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        cl1 = clahe.apply(gray)\n",
    "        \n",
    "        #Subtract background\n",
    "        bgs = cl1-minProj\n",
    "\n",
    "        blur = cv2.GaussianBlur(bgs,blurBlockSize,0)\n",
    "        ret2,th = cv2.threshold(blur,binThresh,255,cv2.THRESH_BINARY_INV)\n",
    "\n",
    "        erode = cv2.erode(th,kernel,iterations=erodeIterations)\n",
    "\n",
    "        dist_transform = cv2.distanceTransform(erode,cv2.DIST_L2,5)\n",
    "        ret3,th2 = cv2.threshold(dist_transform,distFraction*dist_transform.max(),255,0)        \n",
    "        \n",
    "        th2 = 255-th2 \n",
    "        \n",
    "        img = th2\n",
    "        img[img>0]=1\n",
    "        skel = skeletonize(img)\n",
    "        skel = skel.astype(np.uint8)*100\n",
    "        \n",
    "        x,y = [],[]\n",
    "        x,y = np.where(skel>0)\n",
    "        \n",
    "        z = np.polyfit(y, x, polyfit_degree)\n",
    "        p = np.poly1d(z)\n",
    "        polyfit_object.append(p)\n",
    "        polyfit_coeffs.append(z)\n",
    "\n",
    "        xrange.append([min(y),max(y)])\n",
    "        xp = np.linspace(min(y), max(y), numPoints)\n",
    "\n",
    "        points = [[i,j] for i,j in zip(xp,p(xp))]\n",
    "        \n",
    "        tempy = p(xp)\n",
    "        \n",
    "        overlay = cv2.cvtColor(cl1, cv2.COLOR_GRAY2BGR)\n",
    "        cv2.polylines(overlay, np.int32([points]), 0, (0,0,255),1)\n",
    "        \n",
    "        if len(xp)<=5:\n",
    "            drawxp = xp\n",
    "        else:\n",
    "            drawxp = xp[0::int(np.ceil(len(xp)/numDisplayPoints))]\n",
    "                    \n",
    "        for i in range(len(drawxp)):\n",
    "            cv2.circle(overlay,(int(drawxp[i]),int(p(drawxp[i]))), 3, (0,255,255), -1)\n",
    "            \n",
    "        #overlay = cl1.astype(np.uint8)+skel\n",
    "        if savevideo:\n",
    "            out.write(overlay)\n",
    "        \n",
    "        cv2.imshow('Tail Tracking',overlay)\n",
    "        \n",
    "        if cv2.waitKey(dispFrameInterval) & 0xFF == ord('q'):\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "\n",
    "endTime = time.time()\n",
    "\n",
    "print('Reconstruction Completed in {}s'.format(round(endTime-startTime,2)))\n",
    "\n",
    "# Release everything if job is finished\n",
    "cap.release()\n",
    "if savevideo:\n",
    "    out.release()\n",
    "    \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "xapts = []\n",
    "yapts = []\n",
    "for i in range(len(polyfit_object)):\n",
    "    xapt = xrange[i][0]\n",
    "    yapt = polyfit_object[i](xapt)\n",
    "    xapts.append(xapt)\n",
    "    yapts.append(yapt)\n",
    "    \n",
    "anchor = [np.median(xapts),np.median(yapts)]\n",
    "\n",
    "cropped_xlims= []\n",
    "track_points= []\n",
    "for i in range(len(polyfit_object)):\n",
    "\n",
    "    crp_lim = get_nearest_anchor_point(polyfit_object[i],xrange[i],anchor,stepsize=1)\n",
    "    cropped_xlims.append(crp_lim)\n",
    "    \n",
    "    track_points.append(get_evenly_spaced_points(polyfit_object[i],crp_lim,stepsize=10))\n",
    "    \n",
    "\n",
    "if savedata :    \n",
    "    np.savez(outpath+'trackdata.npz', polyfit_coeffs = polyfit_coeffs, track_points = track_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
